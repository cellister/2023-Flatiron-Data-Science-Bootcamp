{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "A company is expanding into new industries to diversify its portfolio. Specifically, they are interested in purchasing and operating airplanes for commercial and private enterprises, but do not know anything about the potential risks of aircrafts. I will be determining which aircrafts are the lowest risk for the company to start this new business endeavor.\n",
    "\n",
    "I will translate my findings into actionable insights that the head of the new aviation division can use to help decide which aircrafts to purchase.\n",
    "\n",
    "## My Approach\n",
    "\n",
    "I will determine which aircrafts have the lowest risk for a company to begin a new business endeavor. To do this, I will start by investigating data on various makes and models of airplanes and their fatality counts to understand a percentage rate of plane model linked to fatality in plane crashes.\n",
    "Next, using that percentage rate and logistical regression models, I’ll explore relationships to plane damage and level of injury in plane investigations to describe a risk.\n",
    "I’ll seek to answer the following questions:\n",
    "1.\tWhich plane model has the lowest rate of fatality? (What plane is a safe choice to limit risk of fatality?) \n",
    "2.\tDuring investigation, which model was found to sustain the least amount of aircraft damage? (Which plane model is the most durable?)\n",
    "3.\tWhat level of injury was found in investigations relating to different plane models? (What plane is a safe choice to limit liability for bodily injuries?)\n",
    "4. FAA regulation liability? Safe Harbor?\n",
    "Finally, I will explore two particular aspects of safety:\n",
    "1.\tA rank of the number of accidents by month and weather.  Knowing which time of year are accidents more likely to happen as a result of weather, can advise the company on heavy or light scheduling of flights.\n",
    "2.\tA look at how the aircraft model correlates to place of accident or incident (broad phase of flight). This could advise which parts of the plane need to be meticulously monitored for performance before and during each flight to prevent investigations.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "Data for this project was obtained from the following repository and also saved in ZippedData folder in this repositpory. \n",
    "\n",
    "The data comes from Kaggle, Aviation Accident Database & Synopses, up to 2023. \n",
    "\n",
    "## Methodology\n",
    "\n",
    "The process can be divided into two stages:\n",
    "\n",
    "A. Data preparation\n",
    "    1. Importing libraries\n",
    "    2. Reading and cleaning provided data\n",
    "    3. Dealing with missing values\n",
    "    4. Joining datasets\n",
    "    5. Scraping additional data and cleaning it\n",
    "\n",
    "B. Visualizations and insights\n",
    "    1. Creating visualizations\n",
    "    2. Drawing conclusions\n",
    "    3. Providing recommendations\n",
    "\n",
    "## Summary\n",
    "\n",
    "This final section includes my findings, key actionable insights, suggested future questions to explore, and any limitations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Provided\n",
    "\n",
    "Data reading\n",
    "\n",
    "The data provided is in the ZippedData folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6e9d716eb56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read in the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maviation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./AviationData.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maviation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#read in the csv file\n",
    "aviation_data = pd.read_csv('./AviationData.csv', index_col=0)\n",
    "aviation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Erin/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (6,7,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Investigation.Type</th>\n",
       "      <th>Accident.Number</th>\n",
       "      <th>Event.Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Airport.Code</th>\n",
       "      <th>Airport.Name</th>\n",
       "      <th>Injury.Severity</th>\n",
       "      <th>...</th>\n",
       "      <th>Purpose.of.flight</th>\n",
       "      <th>Air.carrier</th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Total.Uninjured</th>\n",
       "      <th>Weather.Condition</th>\n",
       "      <th>Broad.phase.of.flight</th>\n",
       "      <th>Report.Status</th>\n",
       "      <th>Publication.Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Event.Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20001218X45444</th>\n",
       "      <td>Accident</td>\n",
       "      <td>SEA87LA080</td>\n",
       "      <td>1948-10-24</td>\n",
       "      <td>MOOSE CREEK, ID</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fatal(2)</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001218X45447</th>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX94LA336</td>\n",
       "      <td>1962-07-19</td>\n",
       "      <td>BRIDGEPORT, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fatal(4)</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>19-09-1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20061025X01555</th>\n",
       "      <td>Accident</td>\n",
       "      <td>NYC07LA005</td>\n",
       "      <td>1974-08-30</td>\n",
       "      <td>Saltville, VA</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.9222</td>\n",
       "      <td>-81.8781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fatal(3)</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>26-02-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001218X45448</th>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX96LA321</td>\n",
       "      <td>1977-06-19</td>\n",
       "      <td>EUREKA, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fatal(2)</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>12-09-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041105X01764</th>\n",
       "      <td>Accident</td>\n",
       "      <td>CHI79FA064</td>\n",
       "      <td>1979-08-02</td>\n",
       "      <td>Canton, OH</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fatal(1)</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Approach</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>16-04-1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Investigation.Type Accident.Number  Event.Date  \\\n",
       "Event.Id                                                        \n",
       "20001218X45444           Accident      SEA87LA080  1948-10-24   \n",
       "20001218X45447           Accident      LAX94LA336  1962-07-19   \n",
       "20061025X01555           Accident      NYC07LA005  1974-08-30   \n",
       "20001218X45448           Accident      LAX96LA321  1977-06-19   \n",
       "20041105X01764           Accident      CHI79FA064  1979-08-02   \n",
       "\n",
       "                       Location        Country Latitude Longitude  \\\n",
       "Event.Id                                                            \n",
       "20001218X45444  MOOSE CREEK, ID  United States      NaN       NaN   \n",
       "20001218X45447   BRIDGEPORT, CA  United States      NaN       NaN   \n",
       "20061025X01555    Saltville, VA  United States  36.9222  -81.8781   \n",
       "20001218X45448       EUREKA, CA  United States      NaN       NaN   \n",
       "20041105X01764       Canton, OH  United States      NaN       NaN   \n",
       "\n",
       "               Airport.Code Airport.Name Injury.Severity  ...  \\\n",
       "Event.Id                                                  ...   \n",
       "20001218X45444          NaN          NaN        Fatal(2)  ...   \n",
       "20001218X45447          NaN          NaN        Fatal(4)  ...   \n",
       "20061025X01555          NaN          NaN        Fatal(3)  ...   \n",
       "20001218X45448          NaN          NaN        Fatal(2)  ...   \n",
       "20041105X01764          NaN          NaN        Fatal(1)  ...   \n",
       "\n",
       "               Purpose.of.flight Air.carrier Total.Fatal.Injuries  \\\n",
       "Event.Id                                                            \n",
       "20001218X45444          Personal         NaN                  2.0   \n",
       "20001218X45447          Personal         NaN                  4.0   \n",
       "20061025X01555          Personal         NaN                  3.0   \n",
       "20001218X45448          Personal         NaN                  2.0   \n",
       "20041105X01764          Personal         NaN                  1.0   \n",
       "\n",
       "               Total.Serious.Injuries Total.Minor.Injuries Total.Uninjured  \\\n",
       "Event.Id                                                                     \n",
       "20001218X45444                    0.0                  0.0             0.0   \n",
       "20001218X45447                    0.0                  0.0             0.0   \n",
       "20061025X01555                    NaN                  NaN             NaN   \n",
       "20001218X45448                    0.0                  0.0             0.0   \n",
       "20041105X01764                    2.0                  NaN             0.0   \n",
       "\n",
       "                Weather.Condition Broad.phase.of.flight   Report.Status  \\\n",
       "Event.Id                                                                  \n",
       "20001218X45444                UNK                Cruise  Probable Cause   \n",
       "20001218X45447                UNK               Unknown  Probable Cause   \n",
       "20061025X01555                IMC                Cruise  Probable Cause   \n",
       "20001218X45448                IMC                Cruise  Probable Cause   \n",
       "20041105X01764                VMC              Approach  Probable Cause   \n",
       "\n",
       "               Publication.Date  \n",
       "Event.Id                         \n",
       "20001218X45444              NaN  \n",
       "20001218X45447       19-09-1996  \n",
       "20061025X01555       26-02-2007  \n",
       "20001218X45448       12-09-2000  \n",
       "20041105X01764       16-04-1980  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the 'AviationData.csv' file using a proper encoding\n",
    "aviation_data = pd.read_csv('./AviationData.csv', index_col=0, header=0, encoding='latin-1')\n",
    "aviation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this error message I notice that the file may have some corrupt or mixed values. Some missing values are labeled as NA, others as N/A or empty. Values are separated with leading and trailing spaces (in some cases).\n",
    "\n",
    "I'll conduct an exploratory data analysis to learn more about the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88889 entries, 20001218X45444 to 20221230106513\n",
      "Data columns (total 30 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Investigation.Type      88889 non-null  object \n",
      " 1   Accident.Number         88889 non-null  object \n",
      " 2   Event.Date              88889 non-null  object \n",
      " 3   Location                88837 non-null  object \n",
      " 4   Country                 88663 non-null  object \n",
      " 5   Latitude                34382 non-null  object \n",
      " 6   Longitude               34373 non-null  object \n",
      " 7   Airport.Code            50249 non-null  object \n",
      " 8   Airport.Name            52790 non-null  object \n",
      " 9   Injury.Severity         87889 non-null  object \n",
      " 10  Aircraft.damage         85695 non-null  object \n",
      " 11  Aircraft.Category       32287 non-null  object \n",
      " 12  Registration.Number     87572 non-null  object \n",
      " 13  Make                    88826 non-null  object \n",
      " 14  Model                   88797 non-null  object \n",
      " 15  Amateur.Built           88787 non-null  object \n",
      " 16  Number.of.Engines       82805 non-null  float64\n",
      " 17  Engine.Type             81812 non-null  object \n",
      " 18  FAR.Description         32023 non-null  object \n",
      " 19  Schedule                12582 non-null  object \n",
      " 20  Purpose.of.flight       82697 non-null  object \n",
      " 21  Air.carrier             16648 non-null  object \n",
      " 22  Total.Fatal.Injuries    77488 non-null  float64\n",
      " 23  Total.Serious.Injuries  76379 non-null  float64\n",
      " 24  Total.Minor.Injuries    76956 non-null  float64\n",
      " 25  Total.Uninjured         82977 non-null  float64\n",
      " 26  Weather.Condition       84397 non-null  object \n",
      " 27  Broad.phase.of.flight   61724 non-null  object \n",
      " 28  Report.Status           82508 non-null  object \n",
      " 29  Publication.Date        75118 non-null  object \n",
      "dtypes: float64(5), object(25)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "aviation_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aviation_data) #just checking to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number.of.Engines</th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Total.Uninjured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82805.000000</td>\n",
       "      <td>77488.000000</td>\n",
       "      <td>76379.000000</td>\n",
       "      <td>76956.000000</td>\n",
       "      <td>82977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.146585</td>\n",
       "      <td>0.647855</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.357061</td>\n",
       "      <td>5.325440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.446510</td>\n",
       "      <td>5.485960</td>\n",
       "      <td>1.544084</td>\n",
       "      <td>2.235625</td>\n",
       "      <td>27.913634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number.of.Engines  Total.Fatal.Injuries  Total.Serious.Injuries  \\\n",
       "count       82805.000000          77488.000000            76379.000000   \n",
       "mean            1.146585              0.647855                0.279881   \n",
       "std             0.446510              5.485960                1.544084   \n",
       "min             0.000000              0.000000                0.000000   \n",
       "25%             1.000000              0.000000                0.000000   \n",
       "50%             1.000000              0.000000                0.000000   \n",
       "75%             1.000000              0.000000                0.000000   \n",
       "max             8.000000            349.000000              161.000000   \n",
       "\n",
       "       Total.Minor.Injuries  Total.Uninjured  \n",
       "count          76956.000000     82977.000000  \n",
       "mean               0.357061         5.325440  \n",
       "std                2.235625        27.913634  \n",
       "min                0.000000         0.000000  \n",
       "25%                0.000000         0.000000  \n",
       "50%                0.000000         1.000000  \n",
       "75%                0.000000         2.000000  \n",
       "max              380.000000       699.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aviation_data.describe() #getting an overview/preview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Fatal    67357\n",
       "Fatal(1)      6167\n",
       "Fatal         5262\n",
       "Fatal(2)      3711\n",
       "Incident      2219\n",
       "             ...  \n",
       "Fatal(68)        1\n",
       "Fatal(35)        1\n",
       "Fatal(31)        1\n",
       "Fatal(55)        1\n",
       "Fatal(47)        1\n",
       "Name: Injury.Severity, Length: 109, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using value counts to check categorical feature's distribution\n",
    "aviation_data['Injury.Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a sense of the data that is available to me, I'll focus on some more specific questions to dig into. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What make and model planes are included in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What data will I use? \n",
    "    #I will need to use the make and model columns\n",
    "#What type of logic and calculation will I use?\n",
    "    #.value_counts() to count the different animal types\n",
    "#What type of visualization would help answer the question?\n",
    "    #a bar chart would be good for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cessna                22227\n",
       "Piper                 12029\n",
       "CESSNA                 4922\n",
       "Beech                  4330\n",
       "PIPER                  2841\n",
       "                      ...  \n",
       "FRITZ                     1\n",
       "Trella                    1\n",
       "HOWARD M. SHEPHERD        1\n",
       "SCHOSANSKI JOHN H         1\n",
       "CONCANNON MILTON          1\n",
       "Name: Make, Length: 8237, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aviation_data['Make'].value_counts() #rename and combine Cessna and any other duplicates .map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152                     2367\n",
       "172                     1756\n",
       "172N                    1164\n",
       "PA-28-140                932\n",
       "150                      829\n",
       "                        ... \n",
       "CASA 1-131E                1\n",
       "2T1A2                      1\n",
       "Stoddard HamiltonSH3       1\n",
       "SZD 51-1 Junior            1\n",
       "FOKKER DR-1                1\n",
       "Name: Model, Length: 12318, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aviation_data['Model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how can I connect these two columns of data? .groupby()? .join()?\n",
    "#make copies of the columns in a new DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aviation_data_clean = aviation_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in aviation_data_clean:\n",
    "    #save the document date to a variable\n",
    "    string_date = x['Event.Date']\n",
    "    \n",
    "    #extract the incident year and month from the string, and cast to int\n",
    "    incident_year = int(string_date[0:4])\n",
    "    incident_month = int(string_date[5:7])\n",
    "    \n",
    "    #add the incident year and month to each row in aviation_data_clean\n",
    "    x['incident_year'] = incident_year\n",
    "    x['incident_month'] = incident_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in aviation_data_clean:\n",
    "    #save the Injury.Severity to a variable\n",
    "    fatality_injury = x['Injury.Severity']\n",
    "    \n",
    "    #extract the incident type and make true or false?\n",
    "    fatality_binary = int(falatity_injury['True'])\n",
    "    \n",
    "    #add the incident year and month to each row in aviation_data_clean\n",
    "    x['fatality_binary'] = fatality_binary\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a copy of 'aviation_data' with the missing values replaced\n",
    "aviation_make_filled = aviation_data_clean.fillna({'Make':'UNKNOWN'}) #for all na values in the make column changes na->UNKNOWN\n",
    "aviation_make_filled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My logic\n",
    "\n",
    "We have a lot of data and the first step is to consider which variables best support conclusions that will produce actionable recommendations; these will be the focus of my investigation. Due to time constraints, I will be first consider variables with more complete data.\n",
    "\n",
    "The variable that stands out to me as the independent variable is make and model of various aircrafts. The dependent variables that I think will best inform on safety are 'Fatality', 'Damage to Plane', and level of injury. Correlations found from these data will be crucial in making an informed decision around which aircrafts to purchase because they most directly relate to the loss of human life. \n",
    "\n",
    "However, I will address in my final summary other variables that can impact safety or partially explain the accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "In this section, I will next the make, model, and fatality columns to make a new DataFrame where a percentage fatality can be calculated that is not biased on the number of samples in this particular data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll prepare the dataframe for further analysis. I'll fix the missing value issue only for the columns I intend to use later and I'll update empty cells consistently with the way unknown values are treated in their respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "#check for null values/missing/placeholder values\n",
    "#check data types, make sure that they are consistent\n",
    "#decide if any rows should be removed\n",
    "#summary info()\n",
    "#calculate the % fatality\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations and Insights\n",
    "\n",
    "Do I reference Tableau? How to I include it in jupyter notebook? Do I have the option of matplotlib or seaborn?\n",
    "\n",
    "#narrate graph and variable choices for each visualtization thoughout section.\n",
    "#describe what I'm seeing on each graph and what it means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Work\n",
    "\n",
    "## Summary of findings\n",
    "\n",
    "### Fatality\n",
    "\n",
    "### Aircraft Damage\n",
    "\n",
    "### Level of injury\n",
    "\n",
    "## Actionable Insights\n",
    "\n",
    "## Future Work\n",
    "\n",
    "As next steps, I would suggest the following:\n",
    "\n",
    "    1. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
